{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cendus_poi = pd.read_pickle('../clean_pickles/target_cendus_poi.pk')\n",
    "df_cendus_poi_sub = pd.read_pickle('../clean_pickles/target_cendus_poi_sub.pk')\n",
    "df_dianping_poi = pd.read_pickle('../clean_pickles/target_dianping_poi.pk')\n",
    "df_dianping_poi_cat = pd.read_pickle('../clean_pickles/target_dianping_poi_cat.pk')\n",
    "df_mobike = pd.read_pickle('../clean_pickles/target_mobike.pk')\n",
    "df_mobike_byhours = pd.read_pickle('../clean_pickles/target_mobike_byhours.pk')\n",
    "df_re = pd.read_pickle('../clean_pickles/target_real_estate.pk')\n",
    "df_taxi = pd.read_pickle('../clean_pickles/target_taxi_speed.pk')\n",
    "df_weibo = pd.read_pickle('../clean_pickles/target_weibo.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_cendus_poi.iloc[:,9:len(df_cendus_poi.columns)]\n",
    "df_pred = df_pred.join(df_cendus_poi_sub.iloc[:,9:len(df_cendus_poi_sub.columns)], rsuffix='_sub')\n",
    "df_pred = df_pred.join(df_dianping_poi.iloc[:,9:len(df_dianping_poi.columns)])\n",
    "df_pred = df_pred.join(df_dianping_poi_cat.iloc[:,9:len(df_dianping_poi_cat.columns)])\n",
    "df_pred = df_pred.join(df_mobike.iloc[:,9:len(df_mobike.columns)])\n",
    "df_pred = df_pred.join(df_mobike_byhours.iloc[:,9:len(df_mobike_byhours.columns)])\n",
    "df_pred = df_pred.join(df_re.iloc[:,9:len(df_re.columns)])\n",
    "df_pred = df_pred.join(df_taxi.iloc[:,9:len(df_taxi.columns)])\n",
    "df_pred = df_pred.join(df_weibo.iloc[:,9:len(df_weibo.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCriteriasNoiseSmell(df):\n",
    "    droppingColumns = []\n",
    "    nb0 = df.iloc[:,len(df.columns)-1].value_counts()[0]\n",
    "    nb1 = df.iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "    ratio = nb1 / nb0\n",
    "    counter = 0\n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        # 10 NA max to remove a maximum of 3 % of the points\n",
    "        if len(df[df.iloc[:,i].isna()]) > 10:\n",
    "            nbi0 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[0]\n",
    "            try:\n",
    "                nbi1 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "            except KeyError:\n",
    "                nbi1 = 0\n",
    "            #if the proportion of the class is kept then we keep the criterion\n",
    "            if (nbi1/nbi0) > ratio:\n",
    "                droppingColumns.append(df.iloc[:,i].name)\n",
    "                counter +=1\n",
    "                print(df.iloc[:,i].name,  len(df[df.iloc[:,i].isna()]))\n",
    "    print(counter)\n",
    "    return df.drop(columns=droppingColumns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCriteriasClean(df):\n",
    "    droppingColumns = []\n",
    "    nb1 = df.iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "    nb2 = df.iloc[:,len(df.columns)-1].value_counts()[2]\n",
    "    nb3 = df.iloc[:,len(df.columns)-1].value_counts()[3]\n",
    "    nb4 = df.iloc[:,len(df.columns)-1].value_counts()[4]\n",
    "    ratio = (nb1+nb4) / (nb2+nb3)\n",
    "    counter = 0\n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        # 10 NA max to remove a maximum of 3 % of the points\n",
    "        if len(df[df.iloc[:,i].isna()]) > 10:\n",
    "            try:\n",
    "                nbi1 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "            except KeyError:\n",
    "                nbi1 = 0\n",
    "            try:\n",
    "                nbi2 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[2]\n",
    "            except KeyError:\n",
    "                nbi2 = 0\n",
    "            try:\n",
    "                nbi3 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[3]\n",
    "            except KeyError:\n",
    "                nbi3 = 0\n",
    "            try:\n",
    "                nbi4 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[4]\n",
    "            except KeyError:\n",
    "                nbi4 = 0\n",
    "            #if the proportion of the class is kept then we keep the criterion\n",
    "            if ( (nbi1+nbi4)/(nbi2+nbi3) ) > ratio:\n",
    "                droppingColumns.append(df.iloc[:,i].name)\n",
    "                counter +=1\n",
    "                print(df.iloc[:,i].name,  len(df[df.iloc[:,i].isna()]))\n",
    "    print(counter)\n",
    "    return df.drop(columns=droppingColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the criteria that have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 18\n",
      "av_decoration_score_dianping 19\n",
      "av_product_score_dianping 19\n",
      "av_service_score_dianping 19\n",
      "av_mobike_duration 47\n",
      "av_mobike_distance 47\n",
      "av_mobike_speed 47\n",
      "av_friends_count_weibo 68\n",
      "av_followers_count_weibo 68\n",
      "av_status_count_weibo 68\n",
      "av_total_checkin_count_weibo 68\n",
      "av_tip_count_weibo 68\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "df_pred_clean = df_pred.join(df_cendus_poi['clean'])\n",
    "df_pred_clean = df_pred_clean.dropna(subset=['clean'])\n",
    "df_pred_clean = cleanCriteriasClean(df_pred_clean)\n",
    "df_pred_clean = df_pred_clean.dropna()\n",
    "df_pred_clean = df_pred_clean.sample(n=len(df_pred_clean), random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 16\n",
      "av_decoration_score_dianping 18\n",
      "av_product_score_dianping 18\n",
      "av_service_score_dianping 18\n",
      "av_mobike_duration 39\n",
      "av_mobike_distance 39\n",
      "av_mobike_speed 39\n",
      "taxi_speed_mean 12\n",
      "av_friends_count_weibo 60\n",
      "av_followers_count_weibo 60\n",
      "av_status_count_weibo 60\n",
      "av_total_checkin_count_weibo 60\n",
      "av_tip_count_weibo 60\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "df_pred_noise = df_pred.join(df_cendus_poi['noise'])\n",
    "df_pred_noise = df_pred_noise.dropna(subset=['noise'])\n",
    "df_pred_noise = cleanCriteriasNoiseSmell(df_pred_noise)\n",
    "df_pred_noise = df_pred_noise.dropna()\n",
    "df_pred_noise = df_pred_noise.sample(n=len(df_pred_noise), random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 18\n",
      "av_decoration_score_dianping 18\n",
      "av_product_score_dianping 18\n",
      "av_service_score_dianping 18\n",
      "av_mobike_duration 43\n",
      "av_mobike_distance 43\n",
      "av_mobike_speed 43\n",
      "av_onesquaremeter_re 16\n",
      "av_bedroom_re 16\n",
      "taxi_speed_mean 12\n",
      "av_friends_count_weibo 63\n",
      "av_followers_count_weibo 63\n",
      "av_status_count_weibo 63\n",
      "av_total_checkin_count_weibo 63\n",
      "av_tip_count_weibo 63\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "df_pred_smell = df_pred.join(df_cendus_poi['smell'])\n",
    "df_pred_smell = df_pred_smell.dropna(subset=['smell'])\n",
    "df_pred_smell = cleanCriteriasNoiseSmell(df_pred_smell)\n",
    "df_pred_smell = df_pred_smell.dropna()\n",
    "df_pred_smell = df_pred_smell.sample(n=len(df_pred_smell), random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_noise.iloc[:,0:len(df_pred_noise.columns)-1].copy()\n",
    "#X = df_pred_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_noise['noise'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    344\n",
       "1.0     87\n",
       "Name: noise, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.81438515081206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "prop[0.0] / (prop[0.0] + prop[1.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7843090082865544"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, n_estimators = 20)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 40, 'n_estimators': 40}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [2,3,4,6,8,10,20,40,50,60], 'n_estimators': [10,20,30,40,60,80]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "search.fit(X,Y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9607997265892003"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=40, n_estimators = 40)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.937007874015748"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=40, n_estimators = 40)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   2],\n",
       "       [  6,   0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_clean.iloc[:,0:len(df_pred_clean.columns)-1].copy()\n",
    "#X = df_cendus_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_clean['clean'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    218\n",
       "2    182\n",
       "4     17\n",
       "1     15\n",
       "Name: clean, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 2 & 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.5925925925926"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "(prop[2.0]+prop[3.0]) / (prop[1.0] + prop[2.0] + prop[3.0] + prop[4.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5044373162256081"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=5, n_estimators = 20)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 40, 'n_estimators': 60}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [2,3,4,6,8,10,20,40,50,60], 'n_estimators': [10,20,30,40,60,80]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "search.fit(X,Y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581681476418318"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=40, n_estimators = 60)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952755905511811"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=40, n_estimators = 60)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952755905511811"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9297053594107187"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,   0],\n",
       "       [  6,   0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    121\n",
       "1.0      6\n",
       "Name: smell, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_smell.iloc[:,0:len(df_pred_smell.columns)-1].copy()\n",
    "#X = df_cendus_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_smell['smell'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    367\n",
       "1.0     16\n",
       "Name: smell, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.822454308094"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "prop[0.0] / (prop[0.0] + prop[1.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634313055365686"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=5, n_estimators = 20)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'n_estimators': 20}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': [2,3,4,6,8,10,20,40,50,60], 'n_estimators': [10,20,30,40,60,80]}\n",
    "search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "search.fit(X,Y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9608339029391659"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=6, n_estimators = 20)\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968503937007874"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)\n",
    "clf = RandomForestClassifier(max_depth=6, n_estimators = 20)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[123,   0],\n",
       "       [  4,   0]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    123\n",
       "1.0      4\n",
       "Name: smell, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    127\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
