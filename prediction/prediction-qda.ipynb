{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cendus_poi = pd.read_pickle('../clean_pickles/target_cendus_poi.pk')\n",
    "df_cendus_poi_sub = pd.read_pickle('../clean_pickles/target_cendus_poi_sub.pk')\n",
    "df_dianping_poi = pd.read_pickle('../clean_pickles/target_dianping_poi.pk')\n",
    "df_dianping_poi_cat = pd.read_pickle('../clean_pickles/target_dianping_poi_cat.pk')\n",
    "df_mobike = pd.read_pickle('../clean_pickles/target_mobike.pk')\n",
    "df_mobike_byhours = pd.read_pickle('../clean_pickles/target_mobike_byhours.pk')\n",
    "df_re = pd.read_pickle('../clean_pickles/target_real_estate.pk')\n",
    "df_taxi = pd.read_pickle('../clean_pickles/target_taxi_speed.pk')\n",
    "df_weibo = pd.read_pickle('../clean_pickles/target_weibo.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_cendus_poi.iloc[:,9:len(df_cendus_poi.columns)]\n",
    "df_pred = df_pred.join(df_cendus_poi_sub.iloc[:,9:len(df_cendus_poi_sub.columns)], rsuffix='_sub')\n",
    "df_pred = df_pred.join(df_dianping_poi.iloc[:,9:len(df_dianping_poi.columns)])\n",
    "df_pred = df_pred.join(df_dianping_poi_cat.iloc[:,9:len(df_dianping_poi_cat.columns)])\n",
    "df_pred = df_pred.join(df_mobike.iloc[:,9:len(df_mobike.columns)])\n",
    "df_pred = df_pred.join(df_mobike_byhours.iloc[:,9:len(df_mobike_byhours.columns)])\n",
    "df_pred = df_pred.join(df_re.iloc[:,9:len(df_re.columns)])\n",
    "df_pred = df_pred.join(df_taxi.iloc[:,9:len(df_taxi.columns)])\n",
    "df_pred = df_pred.join(df_weibo.iloc[:,9:len(df_weibo.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of criterias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCriteriasNoiseSmell(df):\n",
    "    droppingColumns = []\n",
    "    nb0 = df.iloc[:,len(df.columns)-1].value_counts()[0]\n",
    "    nb1 = df.iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "    ratio = nb1 / nb0\n",
    "    counter = 0\n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        # 10 NA max to remove a maximum of 3 % of the points\n",
    "        if len(df[df.iloc[:,i].isna()]) > 10:\n",
    "            nbi0 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[0]\n",
    "            try:\n",
    "                nbi1 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "            except KeyError:\n",
    "                nbi1 = 0\n",
    "            #if the proportion of the class is kept then we keep the criterion\n",
    "            if (nbi1/nbi0) > ratio:\n",
    "                droppingColumns.append(df.iloc[:,i].name)\n",
    "                counter +=1\n",
    "                print(df.iloc[:,i].name,  len(df[df.iloc[:,i].isna()]))\n",
    "    print(counter)\n",
    "    return df.drop(columns=droppingColumns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanCriteriasClean(df):\n",
    "    droppingColumns = []\n",
    "    nb1 = df.iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "    nb2 = df.iloc[:,len(df.columns)-1].value_counts()[2]\n",
    "    nb3 = df.iloc[:,len(df.columns)-1].value_counts()[3]\n",
    "    nb4 = df.iloc[:,len(df.columns)-1].value_counts()[4]\n",
    "    ratio = (nb1+nb4) / (nb2+nb3)\n",
    "    counter = 0\n",
    "    for i in range(0,len(df.columns)-1):\n",
    "        # 10 NA max to remove a maximum of 3 % of the points\n",
    "        if len(df[df.iloc[:,i].isna()]) > 10:\n",
    "            try:\n",
    "                nbi1 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[1]\n",
    "            except KeyError:\n",
    "                nbi1 = 0\n",
    "            try:\n",
    "                nbi2 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[2]\n",
    "            except KeyError:\n",
    "                nbi2 = 0\n",
    "            try:\n",
    "                nbi3 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[3]\n",
    "            except KeyError:\n",
    "                nbi3 = 0\n",
    "            try:\n",
    "                nbi4 = df[df.iloc[:,i].isna()].iloc[:,len(df.columns)-1].value_counts()[4]\n",
    "            except KeyError:\n",
    "                nbi4 = 0\n",
    "            #if the proportion of the class is kept then we keep the criterion\n",
    "            if ( (nbi1+nbi4)/(nbi2+nbi3) ) > ratio:\n",
    "                droppingColumns.append(df.iloc[:,i].name)\n",
    "                counter +=1\n",
    "                print(df.iloc[:,i].name,  len(df[df.iloc[:,i].isna()]))\n",
    "    print(counter)\n",
    "    return df.drop(columns=droppingColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We display the criteria that have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 18\n",
      "av_decoration_score_dianping 19\n",
      "av_product_score_dianping 19\n",
      "av_service_score_dianping 19\n",
      "av_mobike_duration 47\n",
      "av_mobike_distance 47\n",
      "av_mobike_speed 47\n",
      "av_friends_count_weibo 68\n",
      "av_followers_count_weibo 68\n",
      "av_status_count_weibo 68\n",
      "av_total_checkin_count_weibo 68\n",
      "av_tip_count_weibo 68\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "df_pred_clean = df_pred.join(df_cendus_poi['clean'])\n",
    "df_pred_clean = df_pred_clean.dropna(subset=['clean'])\n",
    "df_pred_clean = cleanCriteriasClean(df_pred_clean)\n",
    "df_pred_clean = df_pred_clean.dropna()\n",
    "df_pred_clean = df_pred_clean.sample(n=len(df_pred_clean), random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 16\n",
      "av_decoration_score_dianping 18\n",
      "av_product_score_dianping 18\n",
      "av_service_score_dianping 18\n",
      "av_mobike_duration 39\n",
      "av_mobike_distance 39\n",
      "av_mobike_speed 39\n",
      "taxi_speed_mean 12\n",
      "av_friends_count_weibo 60\n",
      "av_followers_count_weibo 60\n",
      "av_status_count_weibo 60\n",
      "av_total_checkin_count_weibo 60\n",
      "av_tip_count_weibo 60\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "df_pred_noise = df_pred.join(df_cendus_poi['noise'])\n",
    "df_pred_noise = df_pred_noise.dropna(subset=['noise'])\n",
    "df_pred_noise = cleanCriteriasNoiseSmell(df_pred_noise)\n",
    "df_pred_noise = df_pred_noise.dropna()\n",
    "df_pred_noise = df_pred_noise.sample(n=len(df_pred_noise), random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "av_price_dianping 18\n",
      "av_decoration_score_dianping 18\n",
      "av_product_score_dianping 18\n",
      "av_service_score_dianping 18\n",
      "av_mobike_duration 43\n",
      "av_mobike_distance 43\n",
      "av_mobike_speed 43\n",
      "av_onesquaremeter_re 16\n",
      "av_bedroom_re 16\n",
      "taxi_speed_mean 12\n",
      "av_friends_count_weibo 63\n",
      "av_followers_count_weibo 63\n",
      "av_status_count_weibo 63\n",
      "av_total_checkin_count_weibo 63\n",
      "av_tip_count_weibo 63\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "df_pred_smell = df_pred.join(df_cendus_poi['smell'])\n",
    "df_pred_smell = df_pred_smell.dropna(subset=['smell'])\n",
    "df_pred_smell = cleanCriteriasNoiseSmell(df_pred_smell)\n",
    "df_pred_smell = df_pred_smell.dropna()\n",
    "df_pred_smell = df_pred_smell.sample(n=len(df_pred_smell), random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_noise.iloc[:,0:len(df_pred_noise.columns)-1].copy()\n",
    "#X = df_pred_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_noise['noise'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to scale value for QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    344\n",
       "1.0     87\n",
       "Name: noise, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.81438515081206"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "prop[0.0] / (prop[0.0] + prop[1.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8027800053461641"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = QDA()\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8251748251748252"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)\n",
    "clf = QDA()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07407407407407408"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117,   3],\n",
       "       [ 22,   1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would suggest here to do a PCA (Principal component analysis) to remove the correlation between my criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_clean.iloc[:,0:len(df_pred_clean.columns)-1].copy()\n",
    "#X = df_cendus_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_clean['clean'].copy()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    218\n",
       "2    182\n",
       "4     17\n",
       "1     15\n",
       "Name: clean, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 2 & 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.5925925925926"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "(prop[2.0]+prop[3.0]) / (prop[1.0] + prop[2.0] + prop[3.0] + prop[4.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4746591820368885"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "clf = QDA()\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4755244755244755"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)\n",
    "clf = QDA()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4755244755244755"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33803617969743865"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  5,  0],\n",
       "       [ 0,  2, 60,  0],\n",
       "       [ 1,  3, 66,  0],\n",
       "       [ 0,  0,  6,  0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    70\n",
       "2    62\n",
       "4     6\n",
       "1     5\n",
       "Name: clean, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    137\n",
       "2      5\n",
       "1      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pred_smell.iloc[:,0:len(df_pred_smell.columns)-1].copy()\n",
    "#X = df_cendus_noise[['nb_shopping_cendus']].copy()\n",
    "Y = df_pred_smell['smell'].copy()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = MinMaxScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    367\n",
       "1.0     16\n",
       "Name: smell, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of the class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.822454308094"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = Y.value_counts()\n",
    "prop[0.0] / (prop[0.0] + prop[1.0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9477785372522215"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "clf = QDA()\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Roger\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9291338582677166"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.33, shuffle=True)\n",
    "clf = QDA()\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_val)\n",
    "np.mean(Y_pred == Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(Y_val, Y_pred, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[118,   2],\n",
       "       [  7,   0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    120\n",
       "1.0      7\n",
       "Name: smell, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(Y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
